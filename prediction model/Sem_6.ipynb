{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d925c20-e4b8-4f25-9d5f-3e984d8f906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('student_data_semester_6.csv')\n",
    "\n",
    "# Split the data into features and targets\n",
    "X = df.drop(columns=['Student_ID', 'Grade', 'Dropout_Risk_%'])\n",
    "y_grade = df['Grade']\n",
    "y_dropout = df['Dropout_Risk_%']\n",
    "\n",
    "# Convert Grade to numeric (O = 10, A = 9, B = 8, C = 7, D = 6, E = 5, F = 0)\n",
    "grade_mapping = {'O': 10,'E': 9 , 'A': 8, 'B': 7, 'C': 6, 'D': 5,  'F': 0}\n",
    "y_grade = y_grade.map(grade_mapping)\n",
    "\n",
    "# Split data into train and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train_grade, y_test_grade, y_train_dropout, y_test_dropout = train_test_split(\n",
    "    X, y_grade, y_dropout, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Standardize the data (important for deep learning models)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48bb4300-6829-4df0-ace3-4c7cc66ae586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "50/50 [==============================] - 3s 18ms/step - loss: 14.1989 - accuracy: 6.2500e-04 - val_loss: 3.2214 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 2.9931 - accuracy: 0.0000e+00 - val_loss: 2.4637 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/150\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3575 - accuracy: 0.0000e+00 - val_loss: 2.2495 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 2.1887 - accuracy: 0.0000e+00 - val_loss: 2.0210 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/150\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 2.0041 - accuracy: 0.0000e+00 - val_loss: 1.8535 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 1.9160 - accuracy: 0.0000e+00 - val_loss: 1.7624 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/150\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 1.7390 - accuracy: 0.0000e+00 - val_loss: 1.8639 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/150\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1.6545 - accuracy: 0.0000e+00 - val_loss: 1.6450 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 1.5472 - accuracy: 0.0000e+00 - val_loss: 1.5142 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/150\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 1.3982 - accuracy: 0.0000e+00 - val_loss: 1.5361 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/150\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 1.4833 - accuracy: 0.0000e+00 - val_loss: 1.4327 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 1.3875 - accuracy: 0.0000e+00 - val_loss: 1.3826 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/150\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1.2891 - accuracy: 0.0000e+00 - val_loss: 1.4195 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/150\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 1.1835 - accuracy: 0.0000e+00 - val_loss: 1.2386 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/150\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 1.1726 - accuracy: 0.0000e+00 - val_loss: 1.1787 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 1.2139 - accuracy: 0.0000e+00 - val_loss: 1.1640 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 1.0849 - accuracy: 0.0000e+00 - val_loss: 1.1422 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 1.0770 - accuracy: 0.0000e+00 - val_loss: 1.1919 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/150\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 1.0041 - accuracy: 0.0000e+00 - val_loss: 0.9939 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.9841 - accuracy: 6.2500e-04 - val_loss: 0.9877 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.9389 - accuracy: 0.0012 - val_loss: 0.9207 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/150\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.8742 - accuracy: 0.0031 - val_loss: 0.8650 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/150\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.8399 - accuracy: 0.0050 - val_loss: 0.8806 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/150\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.7834 - accuracy: 0.0050 - val_loss: 0.8723 - val_accuracy: 0.0025\n",
      "Epoch 25/150\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.8099 - accuracy: 0.0106 - val_loss: 0.9063 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.7894 - accuracy: 0.0081 - val_loss: 0.8730 - val_accuracy: 0.0025\n",
      "Epoch 27/150\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.7622 - accuracy: 0.0094 - val_loss: 0.8508 - val_accuracy: 0.0025\n",
      "Epoch 28/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.7325 - accuracy: 0.0081 - val_loss: 0.8078 - val_accuracy: 0.0025\n",
      "Epoch 29/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.7326 - accuracy: 0.0119 - val_loss: 0.8523 - val_accuracy: 0.0050\n",
      "Epoch 30/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.7166 - accuracy: 0.0081 - val_loss: 0.8443 - val_accuracy: 0.0050\n",
      "Epoch 31/150\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.7567 - accuracy: 0.0119 - val_loss: 0.7821 - val_accuracy: 0.0050\n",
      "Epoch 32/150\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.7081 - accuracy: 0.0106 - val_loss: 0.7534 - val_accuracy: 0.0075\n",
      "Epoch 33/150\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.6398 - accuracy: 0.0113 - val_loss: 0.7527 - val_accuracy: 0.0050\n",
      "Epoch 34/150\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.6646 - accuracy: 0.0150 - val_loss: 0.7033 - val_accuracy: 0.0025\n",
      "Epoch 35/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.6308 - accuracy: 0.0113 - val_loss: 0.7753 - val_accuracy: 0.0025\n",
      "Epoch 36/150\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.6169 - accuracy: 0.0113 - val_loss: 0.6945 - val_accuracy: 0.0075\n",
      "Epoch 37/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.6328 - accuracy: 0.0162 - val_loss: 0.9027 - val_accuracy: 0.0025\n",
      "Epoch 38/150\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.6560 - accuracy: 0.0113 - val_loss: 0.7030 - val_accuracy: 0.0050\n",
      "Epoch 39/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.5415 - accuracy: 0.0169 - val_loss: 0.7231 - val_accuracy: 0.0025\n",
      "Epoch 40/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.5900 - accuracy: 0.0137 - val_loss: 0.7023 - val_accuracy: 0.0075\n",
      "Epoch 41/150\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.5854 - accuracy: 0.0162 - val_loss: 0.6859 - val_accuracy: 0.0050\n",
      "Epoch 42/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.5512 - accuracy: 0.0181 - val_loss: 0.6972 - val_accuracy: 0.0050\n",
      "Epoch 43/150\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.5970 - accuracy: 0.0144 - val_loss: 0.6681 - val_accuracy: 0.0075\n",
      "Epoch 44/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.6089 - accuracy: 0.0156 - val_loss: 0.6768 - val_accuracy: 0.0075\n",
      "Epoch 45/150\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.5558 - accuracy: 0.0150 - val_loss: 0.6253 - val_accuracy: 0.0075\n",
      "Epoch 46/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.5531 - accuracy: 0.0156 - val_loss: 0.6028 - val_accuracy: 0.0050\n",
      "Epoch 47/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.5727 - accuracy: 0.0156 - val_loss: 0.7146 - val_accuracy: 0.0050\n",
      "Epoch 48/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.5567 - accuracy: 0.0175 - val_loss: 0.5980 - val_accuracy: 0.0100\n",
      "Epoch 49/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.5902 - accuracy: 0.0150 - val_loss: 0.6385 - val_accuracy: 0.0075\n",
      "Epoch 50/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.5389 - accuracy: 0.0150 - val_loss: 0.6460 - val_accuracy: 0.0075\n",
      "Epoch 51/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.5279 - accuracy: 0.0169 - val_loss: 0.6245 - val_accuracy: 0.0050\n",
      "Epoch 52/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.5357 - accuracy: 0.0150 - val_loss: 0.5497 - val_accuracy: 0.0125\n",
      "Epoch 53/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.5235 - accuracy: 0.0200 - val_loss: 0.6226 - val_accuracy: 0.0050\n",
      "Epoch 54/150\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.5140 - accuracy: 0.0162 - val_loss: 0.5234 - val_accuracy: 0.0100\n",
      "Epoch 55/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.4978 - accuracy: 0.0169 - val_loss: 0.5336 - val_accuracy: 0.0050\n",
      "Epoch 56/150\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.5158 - accuracy: 0.0169 - val_loss: 0.5707 - val_accuracy: 0.0050\n",
      "Epoch 57/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.5184 - accuracy: 0.0188 - val_loss: 0.6166 - val_accuracy: 0.0050\n",
      "Epoch 58/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.5069 - accuracy: 0.0162 - val_loss: 0.6481 - val_accuracy: 0.0050\n",
      "Epoch 59/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.5054 - accuracy: 0.0169 - val_loss: 0.5759 - val_accuracy: 0.0075\n",
      "Epoch 60/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.5078 - accuracy: 0.0188 - val_loss: 0.6025 - val_accuracy: 0.0075\n",
      "Epoch 61/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.0200 - val_loss: 0.6398 - val_accuracy: 0.0050\n",
      "Epoch 62/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.0169 - val_loss: 0.5205 - val_accuracy: 0.0125\n",
      "Epoch 63/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.4795 - accuracy: 0.0194 - val_loss: 0.5166 - val_accuracy: 0.0100\n",
      "Epoch 64/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.4863 - accuracy: 0.0194 - val_loss: 0.5885 - val_accuracy: 0.0100\n",
      "Epoch 65/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.4933 - accuracy: 0.0200 - val_loss: 0.5723 - val_accuracy: 0.0075\n",
      "Epoch 66/150\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.4541 - accuracy: 0.0162 - val_loss: 0.5228 - val_accuracy: 0.0125\n",
      "Epoch 67/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.4743 - accuracy: 0.0188 - val_loss: 0.4810 - val_accuracy: 0.0150\n",
      "Epoch 68/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.4753 - accuracy: 0.0206 - val_loss: 0.5750 - val_accuracy: 0.0050\n",
      "Epoch 69/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.0194 - val_loss: 0.4965 - val_accuracy: 0.0125\n",
      "Epoch 70/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.0188 - val_loss: 0.5970 - val_accuracy: 0.0050\n",
      "Epoch 71/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.5079 - accuracy: 0.0200 - val_loss: 0.5068 - val_accuracy: 0.0075\n",
      "Epoch 72/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.4628 - accuracy: 0.0194 - val_loss: 0.4982 - val_accuracy: 0.0100\n",
      "Epoch 73/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.4318 - accuracy: 0.0188 - val_loss: 0.4982 - val_accuracy: 0.0100\n",
      "Epoch 74/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.0181 - val_loss: 0.5044 - val_accuracy: 0.0100\n",
      "Epoch 75/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.4476 - accuracy: 0.0169 - val_loss: 0.4799 - val_accuracy: 0.0150\n",
      "Epoch 76/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.4344 - accuracy: 0.0206 - val_loss: 0.4887 - val_accuracy: 0.0100\n",
      "Epoch 77/150\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.4272 - accuracy: 0.0200 - val_loss: 0.4777 - val_accuracy: 0.0100\n",
      "Epoch 78/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.4381 - accuracy: 0.0181 - val_loss: 0.4708 - val_accuracy: 0.0175\n",
      "Epoch 79/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.4179 - accuracy: 0.0206 - val_loss: 0.5451 - val_accuracy: 0.0125\n",
      "Epoch 80/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.4309 - accuracy: 0.0206 - val_loss: 0.5335 - val_accuracy: 0.0125\n",
      "Epoch 81/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.4102 - accuracy: 0.0181 - val_loss: 0.5927 - val_accuracy: 0.0125\n",
      "Epoch 82/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.4217 - accuracy: 0.0213 - val_loss: 0.5427 - val_accuracy: 0.0100\n",
      "Epoch 83/150\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.4212 - accuracy: 0.0194 - val_loss: 0.4707 - val_accuracy: 0.0150\n",
      "Epoch 84/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3940 - accuracy: 0.0194 - val_loss: 0.4923 - val_accuracy: 0.0125\n",
      "Epoch 85/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.0206 - val_loss: 0.4719 - val_accuracy: 0.0150\n",
      "Epoch 86/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3793 - accuracy: 0.0200 - val_loss: 0.4435 - val_accuracy: 0.0150\n",
      "Epoch 87/150\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.4009 - accuracy: 0.0200 - val_loss: 0.4201 - val_accuracy: 0.0100\n",
      "Epoch 88/150\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.3994 - accuracy: 0.0181 - val_loss: 0.4451 - val_accuracy: 0.0100\n",
      "Epoch 89/150\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.4011 - accuracy: 0.0194 - val_loss: 0.5323 - val_accuracy: 0.0075\n",
      "Epoch 90/150\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3713 - accuracy: 0.0206 - val_loss: 0.4956 - val_accuracy: 0.0125\n",
      "Epoch 91/150\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.3762 - accuracy: 0.0200 - val_loss: 0.5022 - val_accuracy: 0.0150\n",
      "Epoch 92/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3772 - accuracy: 0.0194 - val_loss: 0.4686 - val_accuracy: 0.0125\n",
      "Epoch 93/150\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3770 - accuracy: 0.0188 - val_loss: 0.4911 - val_accuracy: 0.0175\n",
      "Epoch 94/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3397 - accuracy: 0.0188 - val_loss: 0.4392 - val_accuracy: 0.0125\n",
      "Epoch 95/150\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.0200 - val_loss: 0.5066 - val_accuracy: 0.0100\n",
      "Epoch 96/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3607 - accuracy: 0.0175 - val_loss: 0.4815 - val_accuracy: 0.0125\n",
      "Epoch 97/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3733 - accuracy: 0.0181 - val_loss: 0.4500 - val_accuracy: 0.0200\n",
      "Epoch 98/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3621 - accuracy: 0.0213 - val_loss: 0.4435 - val_accuracy: 0.0150\n",
      "Epoch 99/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3596 - accuracy: 0.0188 - val_loss: 0.5270 - val_accuracy: 0.0075\n",
      "Epoch 100/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3839 - accuracy: 0.0213 - val_loss: 0.4466 - val_accuracy: 0.0150\n",
      "Epoch 101/150\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.3457 - accuracy: 0.0213 - val_loss: 0.4866 - val_accuracy: 0.0050\n",
      "Epoch 102/150\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.3563 - accuracy: 0.0200 - val_loss: 0.4707 - val_accuracy: 0.0175\n",
      "Epoch 103/150\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.3398 - accuracy: 0.0194 - val_loss: 0.4606 - val_accuracy: 0.0075\n",
      "Epoch 104/150\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.0188 - val_loss: 0.4287 - val_accuracy: 0.0100\n",
      "Epoch 105/150\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3546 - accuracy: 0.0194 - val_loss: 0.4934 - val_accuracy: 0.0075\n",
      "Epoch 106/150\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3624 - accuracy: 0.0219 - val_loss: 0.5121 - val_accuracy: 0.0075\n",
      "Epoch 107/150\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3468 - accuracy: 0.0194 - val_loss: 0.3977 - val_accuracy: 0.0225\n",
      "Epoch 108/150\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3478 - accuracy: 0.0213 - val_loss: 0.4795 - val_accuracy: 0.0125\n",
      "Epoch 109/150\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.3515 - accuracy: 0.0169 - val_loss: 0.4761 - val_accuracy: 0.0125\n",
      "Epoch 110/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3379 - accuracy: 0.0219 - val_loss: 0.4088 - val_accuracy: 0.0200\n",
      "Epoch 111/150\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3088 - accuracy: 0.0200 - val_loss: 0.4665 - val_accuracy: 0.0150\n",
      "Epoch 112/150\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3279 - accuracy: 0.0213 - val_loss: 0.4159 - val_accuracy: 0.0175\n",
      "Epoch 113/150\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.3603 - accuracy: 0.0200 - val_loss: 0.4732 - val_accuracy: 0.0100\n",
      "Epoch 114/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3335 - accuracy: 0.0213 - val_loss: 0.5774 - val_accuracy: 0.0150\n",
      "Epoch 115/150\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.3378 - accuracy: 0.0206 - val_loss: 0.3907 - val_accuracy: 0.0175\n",
      "Epoch 116/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3378 - accuracy: 0.0206 - val_loss: 0.3820 - val_accuracy: 0.0175\n",
      "Epoch 117/150\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.3608 - accuracy: 0.0169 - val_loss: 0.4599 - val_accuracy: 0.0075\n",
      "Epoch 118/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3225 - accuracy: 0.0194 - val_loss: 0.4772 - val_accuracy: 0.0150\n",
      "Epoch 119/150\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.3119 - accuracy: 0.0206 - val_loss: 0.4269 - val_accuracy: 0.0175\n",
      "Epoch 120/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3608 - accuracy: 0.0200 - val_loss: 0.4796 - val_accuracy: 0.0150\n",
      "Epoch 121/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3349 - accuracy: 0.0188 - val_loss: 0.4732 - val_accuracy: 0.0175\n",
      "Epoch 122/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3431 - accuracy: 0.0181 - val_loss: 0.6497 - val_accuracy: 0.0050\n",
      "Epoch 123/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3183 - accuracy: 0.0206 - val_loss: 0.5837 - val_accuracy: 0.0050\n",
      "Epoch 124/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3096 - accuracy: 0.0188 - val_loss: 0.5369 - val_accuracy: 0.0100\n",
      "Epoch 125/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3461 - accuracy: 0.0188 - val_loss: 0.4643 - val_accuracy: 0.0175\n",
      "Epoch 126/150\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3106 - accuracy: 0.0206 - val_loss: 0.5265 - val_accuracy: 0.0075\n",
      "Epoch 127/150\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3079 - accuracy: 0.0188 - val_loss: 0.4811 - val_accuracy: 0.0100\n",
      "Epoch 128/150\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2956 - accuracy: 0.0213 - val_loss: 0.4925 - val_accuracy: 0.0100\n",
      "Epoch 129/150\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.3241 - accuracy: 0.0213 - val_loss: 0.4414 - val_accuracy: 0.0125\n",
      "Epoch 130/150\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.3109 - accuracy: 0.0188 - val_loss: 0.4337 - val_accuracy: 0.0175\n",
      "Epoch 131/150\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.2941 - accuracy: 0.0175 - val_loss: 0.4714 - val_accuracy: 0.0150\n",
      "Epoch 132/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3132 - accuracy: 0.0181 - val_loss: 0.4990 - val_accuracy: 0.0050\n",
      "Epoch 133/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3031 - accuracy: 0.0206 - val_loss: 0.4992 - val_accuracy: 0.0075\n",
      "Epoch 134/150\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.3261 - accuracy: 0.0194 - val_loss: 0.4611 - val_accuracy: 0.0100\n",
      "Epoch 135/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3121 - accuracy: 0.0194 - val_loss: 0.5174 - val_accuracy: 0.0050\n",
      "Epoch 136/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.2944 - accuracy: 0.0175 - val_loss: 0.4707 - val_accuracy: 0.0150\n",
      "Epoch 137/150\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.3124 - accuracy: 0.0194 - val_loss: 0.4100 - val_accuracy: 0.0150\n",
      "Epoch 138/150\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.3165 - accuracy: 0.0188 - val_loss: 0.4307 - val_accuracy: 0.0125\n",
      "Epoch 139/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.2993 - accuracy: 0.0188 - val_loss: 0.4188 - val_accuracy: 0.0100\n",
      "Epoch 140/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3074 - accuracy: 0.0181 - val_loss: 0.4628 - val_accuracy: 0.0100\n",
      "Epoch 141/150\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.2934 - accuracy: 0.0188 - val_loss: 0.5595 - val_accuracy: 0.0075\n",
      "Epoch 142/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.2953 - accuracy: 0.0200 - val_loss: 0.4992 - val_accuracy: 0.0075\n",
      "Epoch 143/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3025 - accuracy: 0.0200 - val_loss: 0.4919 - val_accuracy: 0.0125\n",
      "Epoch 144/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.2975 - accuracy: 0.0200 - val_loss: 0.5249 - val_accuracy: 0.0125\n",
      "Epoch 145/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.2580 - accuracy: 0.0200 - val_loss: 0.4716 - val_accuracy: 0.0075\n",
      "Epoch 146/150\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.2770 - accuracy: 0.0181 - val_loss: 0.4900 - val_accuracy: 0.0125\n",
      "Epoch 147/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.2810 - accuracy: 0.0194 - val_loss: 0.5050 - val_accuracy: 0.0100\n",
      "Epoch 148/150\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.2854 - accuracy: 0.0188 - val_loss: 0.5229 - val_accuracy: 0.0050\n",
      "Epoch 149/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.2781 - accuracy: 0.0181 - val_loss: 0.4890 - val_accuracy: 0.0100\n",
      "Epoch 150/150\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.2689 - accuracy: 0.0206 - val_loss: 0.4399 - val_accuracy: 0.0075\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "Deep Learning Grade Prediction Accuracy: 71.25%\n"
     ]
    }
   ],
   "source": [
    " import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Build the neural network model\n",
    "grade_model = Sequential()\n",
    "\n",
    "# Input layer\n",
    "grade_model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "\n",
    "# Hidden layers\n",
    "grade_model.add(Dense(128, activation='relu'))\n",
    "grade_model.add(Dropout(0.2))\n",
    "grade_model.add(Dense(64, activation='relu'))\n",
    "grade_model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "grade_model.add(Dense(1, activation='linear'))  # For regression to predict grade numerically\n",
    "\n",
    "# Compile the model\n",
    "grade_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "grade_model.fit(X_train_scaled, y_train_grade, epochs=150, batch_size=32, validation_data=(X_test_scaled, y_test_grade))\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_grade = grade_model.predict(X_test_scaled)\n",
    "y_pred_grade = y_pred_grade.round()  # Convert continuous output to nearest grade (0-10)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_grade, y_pred_grade)\n",
    "\n",
    "print(f\"Deep Learning Grade Prediction Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bfde3d8-e1a3-4016-899e-ecee3b92bad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 [==============================] - 3s 18ms/step - loss: 807.8152 - mae: 19.9901 - val_loss: 152.4129 - val_mae: 9.9849\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 95.1000 - mae: 7.2359 - val_loss: 39.5453 - val_mae: 4.8682\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 56.8523 - mae: 5.3308 - val_loss: 39.4769 - val_mae: 4.8775\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 56.1161 - mae: 5.3177 - val_loss: 36.2286 - val_mae: 4.7093\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 51.4343 - mae: 5.1624 - val_loss: 36.8172 - val_mae: 4.7482\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 53.1026 - mae: 5.2265 - val_loss: 36.9431 - val_mae: 4.7494\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 53.8591 - mae: 5.2120 - val_loss: 38.2751 - val_mae: 4.7696\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 51.0595 - mae: 5.0768 - val_loss: 35.4146 - val_mae: 4.6473\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 52.1784 - mae: 5.0323 - val_loss: 39.7223 - val_mae: 4.8479\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 49.1131 - mae: 4.9903 - val_loss: 35.7356 - val_mae: 4.6017\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 44.0354 - mae: 4.8176 - val_loss: 41.4991 - val_mae: 4.8650\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 48.8102 - mae: 4.9437 - val_loss: 35.0462 - val_mae: 4.6127\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 42.9545 - mae: 4.6194 - val_loss: 35.5880 - val_mae: 4.5461\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 45.9947 - mae: 4.7382 - val_loss: 35.0130 - val_mae: 4.5876\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 44.5155 - mae: 4.6976 - val_loss: 34.4407 - val_mae: 4.5685\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 44.8434 - mae: 4.6332 - val_loss: 33.5955 - val_mae: 4.4633\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 40.0298 - mae: 4.4162 - val_loss: 37.2612 - val_mae: 4.6453\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 40.4976 - mae: 4.4808 - val_loss: 38.4346 - val_mae: 4.7666\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 41.1012 - mae: 4.5133 - val_loss: 34.2742 - val_mae: 4.5354\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 38.3848 - mae: 4.3549 - val_loss: 34.4993 - val_mae: 4.4234\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 39.1021 - mae: 4.3134 - val_loss: 35.7681 - val_mae: 4.5006\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 40.4698 - mae: 4.3415 - val_loss: 34.2935 - val_mae: 4.5302\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 38.9351 - mae: 4.2564 - val_loss: 35.7305 - val_mae: 4.4183\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 36.7928 - mae: 4.2526 - val_loss: 32.7435 - val_mae: 4.2962\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 39.2668 - mae: 4.2954 - val_loss: 34.0664 - val_mae: 4.4577\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 37.6449 - mae: 4.2116 - val_loss: 33.0333 - val_mae: 4.3820\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 35.8923 - mae: 4.1046 - val_loss: 32.6507 - val_mae: 4.3646\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 34.2736 - mae: 4.0300 - val_loss: 33.4811 - val_mae: 4.3459\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 33.9224 - mae: 4.0429 - val_loss: 34.8672 - val_mae: 4.4027\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 32.5645 - mae: 3.9117 - val_loss: 35.8789 - val_mae: 4.4665\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 34.8827 - mae: 3.9776 - val_loss: 33.1035 - val_mae: 4.2873\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 35.0534 - mae: 3.9608 - val_loss: 36.9717 - val_mae: 4.5271\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 31.4073 - mae: 3.9108 - val_loss: 36.8519 - val_mae: 4.4504\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 34.5947 - mae: 3.8944 - val_loss: 37.5170 - val_mae: 4.4162\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 29.5805 - mae: 3.7230 - val_loss: 36.9810 - val_mae: 4.4831\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 29.1294 - mae: 3.7182 - val_loss: 39.4958 - val_mae: 4.5716\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 32.9010 - mae: 3.8653 - val_loss: 35.3266 - val_mae: 4.4818\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 32.4263 - mae: 3.8480 - val_loss: 35.0595 - val_mae: 4.3625\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 28.3245 - mae: 3.6985 - val_loss: 36.8033 - val_mae: 4.4734\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 32.0886 - mae: 3.7906 - val_loss: 38.4998 - val_mae: 4.5298\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 30.1691 - mae: 3.7362 - val_loss: 39.0729 - val_mae: 4.5386\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 28.5003 - mae: 3.6289 - val_loss: 35.3214 - val_mae: 4.4515\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 27.2417 - mae: 3.5783 - val_loss: 37.0604 - val_mae: 4.4090\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 23.5384 - mae: 3.3728 - val_loss: 35.9294 - val_mae: 4.4394\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 28.7445 - mae: 3.6628 - val_loss: 35.0669 - val_mae: 4.4285\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 27.2205 - mae: 3.4486 - val_loss: 35.0499 - val_mae: 4.3693\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 29.5382 - mae: 3.6210 - val_loss: 41.2323 - val_mae: 4.5794\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 29.0135 - mae: 3.6367 - val_loss: 46.2056 - val_mae: 4.8395\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 30.4514 - mae: 3.6774 - val_loss: 40.6414 - val_mae: 4.5312\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 27.7334 - mae: 3.5294 - val_loss: 37.7515 - val_mae: 4.4549\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 30.7585 - mae: 3.6808 - val_loss: 52.6630 - val_mae: 5.0785\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 28.4290 - mae: 3.6473 - val_loss: 38.1103 - val_mae: 4.5512\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 24.8063 - mae: 3.3872 - val_loss: 39.6393 - val_mae: 4.4880\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 26.4271 - mae: 3.4839 - val_loss: 38.9925 - val_mae: 4.6080\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 24.2430 - mae: 3.3618 - val_loss: 38.5916 - val_mae: 4.5237\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 24.0391 - mae: 3.2897 - val_loss: 38.9479 - val_mae: 4.6422\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 23.0873 - mae: 3.3343 - val_loss: 39.2539 - val_mae: 4.6090\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 28.8925 - mae: 3.5020 - val_loss: 39.8612 - val_mae: 4.5557\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 24.3806 - mae: 3.3495 - val_loss: 39.9409 - val_mae: 4.6743\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 23.1938 - mae: 3.2798 - val_loss: 39.0870 - val_mae: 4.6116\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 24.4082 - mae: 3.3035 - val_loss: 40.7515 - val_mae: 4.6452\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 23.2713 - mae: 3.2321 - val_loss: 40.4497 - val_mae: 4.7038\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 25.1421 - mae: 3.3530 - val_loss: 39.8991 - val_mae: 4.6603\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 22.5418 - mae: 3.2603 - val_loss: 40.1504 - val_mae: 4.7014\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 22.3773 - mae: 3.2382 - val_loss: 40.9549 - val_mae: 4.7070\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 22.5697 - mae: 3.2265 - val_loss: 45.3951 - val_mae: 4.7938\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 23.0493 - mae: 3.1939 - val_loss: 41.9314 - val_mae: 4.7477\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 25.9666 - mae: 3.4371 - val_loss: 40.1607 - val_mae: 4.6232\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 24.6849 - mae: 3.3658 - val_loss: 43.1760 - val_mae: 4.8639\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 23.1515 - mae: 3.3168 - val_loss: 42.0279 - val_mae: 4.7352\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 24.7344 - mae: 3.3838 - val_loss: 42.4714 - val_mae: 4.7631\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 24.1331 - mae: 3.2342 - val_loss: 42.6055 - val_mae: 4.7601\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 20.7291 - mae: 3.0762 - val_loss: 39.9832 - val_mae: 4.6710\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 21.0315 - mae: 3.0886 - val_loss: 43.0333 - val_mae: 4.7199\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 22.3151 - mae: 3.1568 - val_loss: 39.4372 - val_mae: 4.6069\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 21.2920 - mae: 3.1219 - val_loss: 41.6042 - val_mae: 4.5929\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 22.7064 - mae: 3.1206 - val_loss: 41.2064 - val_mae: 4.6620\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 23.0337 - mae: 3.1635 - val_loss: 42.8347 - val_mae: 4.8355\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 19.2471 - mae: 2.9932 - val_loss: 41.2765 - val_mae: 4.6906\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 21.6875 - mae: 3.0163 - val_loss: 50.7285 - val_mae: 4.9070\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 22.0927 - mae: 3.1377 - val_loss: 43.4381 - val_mae: 4.8409\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 22.2561 - mae: 3.1984 - val_loss: 44.1336 - val_mae: 4.7388\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 22.3145 - mae: 3.2016 - val_loss: 42.5202 - val_mae: 4.7751\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 20.9309 - mae: 3.0060 - val_loss: 41.4294 - val_mae: 4.7124\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 18.6405 - mae: 2.9739 - val_loss: 42.7376 - val_mae: 4.7753\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 21.4624 - mae: 3.1354 - val_loss: 43.1343 - val_mae: 4.7241\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 22.5346 - mae: 3.0401 - val_loss: 46.8181 - val_mae: 4.8861\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 21.0832 - mae: 3.1712 - val_loss: 45.4176 - val_mae: 4.9115\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 20.7236 - mae: 3.0677 - val_loss: 44.1107 - val_mae: 4.9067\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 18.7825 - mae: 2.9647 - val_loss: 44.7159 - val_mae: 4.8419\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 16.9005 - mae: 2.8252 - val_loss: 45.7887 - val_mae: 4.8909\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 19.9104 - mae: 3.0049 - val_loss: 45.2970 - val_mae: 4.8206\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 20.6201 - mae: 3.0425 - val_loss: 45.6363 - val_mae: 4.9201\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 20.0305 - mae: 3.0214 - val_loss: 48.9548 - val_mae: 5.0215\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 21.0036 - mae: 3.0825 - val_loss: 45.8384 - val_mae: 4.9502\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 19.1870 - mae: 2.9191 - val_loss: 44.4340 - val_mae: 4.8047\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 20.0303 - mae: 2.9705 - val_loss: 43.8490 - val_mae: 4.8764\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 23.4429 - mae: 3.1557 - val_loss: 46.0649 - val_mae: 4.9802\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 17.9759 - mae: 2.9278 - val_loss: 45.1348 - val_mae: 4.9824\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 21.9854 - mae: 3.0474 - val_loss: 44.0164 - val_mae: 4.9050\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "Deep Learning Dropout Risk RMSE: 6.63\n",
      "Deep Learning Dropout Risk R-squared: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Build the neural network model for dropout risk prediction\n",
    "dropout_model = Sequential()\n",
    "\n",
    "# Input layer\n",
    "dropout_model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "\n",
    "# Hidden layers\n",
    "dropout_model.add(Dense(128, activation='relu'))\n",
    "dropout_model.add(Dropout(0.2))\n",
    "dropout_model.add(Dense(64, activation='relu'))\n",
    "dropout_model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "dropout_model.add(Dense(1, activation='linear'))  # For regression to predict dropout risk\n",
    "\n",
    "# Compile the model\n",
    "dropout_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "dropout_model.fit(X_train_scaled, y_train_dropout, epochs=100, batch_size=32, validation_data=(X_test_scaled, y_test_dropout))\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_dropout = dropout_model.predict(X_test_scaled)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Calculate RMSE (Root Mean Squared Error)\n",
    "dropout_rmse = mean_squared_error(y_test_dropout, y_pred_dropout) ** 0.5\n",
    "\n",
    "# Calculate R-squared score\n",
    "dropout_r2 = r2_score(y_test_dropout, y_pred_dropout)\n",
    "\n",
    "print(f\"Deep Learning Dropout Risk RMSE: {dropout_rmse:.2f}\")\n",
    "print(f\"Deep Learning Dropout Risk R-squared: {dropout_r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eac7da92-5e45-497a-83da-526837ba6a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Actual Grades  Predicted Grades  Actual Dropout Risk  \\\n",
      "1860              5               5.0                81.07   \n",
      "353               9               8.0                 6.96   \n",
      "1333              5               5.0                81.07   \n",
      "905               8               8.0                14.99   \n",
      "1289              8               8.0                11.45   \n",
      "1273              6               6.0                49.80   \n",
      "938               6               5.0                46.96   \n",
      "1731              9               9.0                 3.78   \n",
      "65                5               5.0                78.23   \n",
      "1323              6               6.0                47.67   \n",
      "\n",
      "      Predicted Dropout Risk  \n",
      "1860               87.472054  \n",
      "353                 5.411403  \n",
      "1333               62.219673  \n",
      "905                18.808758  \n",
      "1289               10.746274  \n",
      "1273               62.297657  \n",
      "938                54.288181  \n",
      "1731                3.524431  \n",
      "65                 69.522995  \n",
      "1323               51.084042  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame to compare the actual and predicted values\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual Grades': y_test_grade,\n",
    "    'Predicted Grades': y_pred_grade.flatten(),  # Flatten the predictions array\n",
    "    'Actual Dropout Risk': y_test_dropout,\n",
    "    'Predicted Dropout Risk': y_pred_dropout.flatten()  # Flatten the predictions array\n",
    "})\n",
    "\n",
    "# Display the first 10 rows to compare\n",
    "print(comparison_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6755b608-32f7-400e-9837-4778b512b86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save the grade prediction model\n",
    "grade_model.save('grade_prediction_model6.h5')\n",
    "\n",
    "# Save the dropout risk prediction model\n",
    "dropout_model.save('dropout_risk_prediction_model6.h5')\n",
    "\n",
    "print(\"Models saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513c7531-0d27-4e24-bc9f-c675f21fd84e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
