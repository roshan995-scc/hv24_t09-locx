{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b4dfaab-aa75-44d5-92d9-076598feef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('student_data_semester_1.csv')\n",
    "\n",
    "# Split the data into features and targets\n",
    "X = df.drop(columns=['Student_ID', 'Grade', 'Dropout_Risk_%'])\n",
    "y_grade = df['Grade']\n",
    "y_dropout = df['Dropout_Risk_%']\n",
    "\n",
    "# Convert Grade to numeric (O = 10, A = 9, B = 8, C = 7, D = 6, E = 5, F = 0)\n",
    "grade_mapping = {'O': 10,'E': 9 , 'A': 8, 'B': 7, 'C': 6, 'D': 5,  'F': 0}\n",
    "y_grade = y_grade.map(grade_mapping)\n",
    "\n",
    "# Split data into train and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train_grade, y_test_grade, y_train_dropout, y_test_dropout = train_test_split(\n",
    "    X, y_grade, y_dropout, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Standardize the data (important for deep learning models)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "680d9649-3a57-41b8-adcb-91eeacec328f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50/50 [==============================] - 2s 14ms/step - loss: 14.9669 - accuracy: 0.0031 - val_loss: 3.3098 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 3.3229 - accuracy: 0.0000e+00 - val_loss: 2.2813 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 2.6530 - accuracy: 0.0000e+00 - val_loss: 2.0158 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 2.4788 - accuracy: 0.0000e+00 - val_loss: 1.8446 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 2.3393 - accuracy: 0.0000e+00 - val_loss: 1.8038 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1.9506 - accuracy: 0.0000e+00 - val_loss: 1.6413 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 1.9730 - accuracy: 0.0000e+00 - val_loss: 1.5217 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 1.7730 - accuracy: 0.0000e+00 - val_loss: 1.3468 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 1.6827 - accuracy: 0.0000e+00 - val_loss: 1.2886 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 1.5532 - accuracy: 0.0000e+00 - val_loss: 1.1878 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 1.4180 - accuracy: 0.0012 - val_loss: 1.2049 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 1.3574 - accuracy: 0.0019 - val_loss: 1.0209 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 1.3103 - accuracy: 0.0019 - val_loss: 0.8982 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 1.1388 - accuracy: 0.0044 - val_loss: 0.8366 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 1.1360 - accuracy: 0.0056 - val_loss: 0.7787 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 1.0845 - accuracy: 0.0050 - val_loss: 0.7516 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 1.0443 - accuracy: 0.0063 - val_loss: 0.7077 - val_accuracy: 0.0075\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.9983 - accuracy: 0.0069 - val_loss: 0.6682 - val_accuracy: 0.0075\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.9398 - accuracy: 0.0081 - val_loss: 0.6708 - val_accuracy: 0.0050\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.9205 - accuracy: 0.0119 - val_loss: 0.7370 - val_accuracy: 0.0075\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.8915 - accuracy: 0.0106 - val_loss: 0.8042 - val_accuracy: 0.0025\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.8943 - accuracy: 0.0063 - val_loss: 0.5932 - val_accuracy: 0.0075\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.9028 - accuracy: 0.0144 - val_loss: 0.5821 - val_accuracy: 0.0075\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.8334 - accuracy: 0.0113 - val_loss: 0.5632 - val_accuracy: 0.0075\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.7638 - accuracy: 0.0169 - val_loss: 0.5610 - val_accuracy: 0.0075\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.6797 - accuracy: 0.0150 - val_loss: 0.4674 - val_accuracy: 0.0075\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.7618 - accuracy: 0.0162 - val_loss: 0.4642 - val_accuracy: 0.0075\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.7576 - accuracy: 0.0156 - val_loss: 0.4880 - val_accuracy: 0.0075\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.7022 - accuracy: 0.0156 - val_loss: 0.4598 - val_accuracy: 0.0075\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.7667 - accuracy: 0.0162 - val_loss: 0.4409 - val_accuracy: 0.0075\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.7188 - accuracy: 0.0156 - val_loss: 0.4482 - val_accuracy: 0.0075\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.7557 - accuracy: 0.0188 - val_loss: 0.4914 - val_accuracy: 0.0075\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.6437 - accuracy: 0.0200 - val_loss: 0.4219 - val_accuracy: 0.0075\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.7228 - accuracy: 0.0175 - val_loss: 0.4132 - val_accuracy: 0.0075\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.7410 - accuracy: 0.0175 - val_loss: 0.3640 - val_accuracy: 0.0075\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.6458 - accuracy: 0.0206 - val_loss: 0.3854 - val_accuracy: 0.0075\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.6401 - accuracy: 0.0175 - val_loss: 0.3763 - val_accuracy: 0.0075\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.6382 - accuracy: 0.0181 - val_loss: 0.3781 - val_accuracy: 0.0100\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.6220 - accuracy: 0.0213 - val_loss: 0.3896 - val_accuracy: 0.0075\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.6167 - accuracy: 0.0250 - val_loss: 0.4296 - val_accuracy: 0.0075\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.5769 - accuracy: 0.0188 - val_loss: 0.3896 - val_accuracy: 0.0100\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.6007 - accuracy: 0.0213 - val_loss: 0.4307 - val_accuracy: 0.0100\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.6410 - accuracy: 0.0213 - val_loss: 0.3699 - val_accuracy: 0.0100\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.5960 - accuracy: 0.0194 - val_loss: 0.3602 - val_accuracy: 0.0100\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.5897 - accuracy: 0.0237 - val_loss: 0.3840 - val_accuracy: 0.0100\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.5527 - accuracy: 0.0181 - val_loss: 0.3733 - val_accuracy: 0.0075\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.6182 - accuracy: 0.0244 - val_loss: 0.3994 - val_accuracy: 0.0100\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.5706 - accuracy: 0.0231 - val_loss: 0.3734 - val_accuracy: 0.0100\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.5858 - accuracy: 0.0231 - val_loss: 0.4411 - val_accuracy: 0.0075\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.5252 - accuracy: 0.0231 - val_loss: 0.3455 - val_accuracy: 0.0100\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "Deep Learning Grade Prediction Accuracy: 76.75%\n"
     ]
    }
   ],
   "source": [
    " import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Build the neural network model\n",
    "grade_model = Sequential()\n",
    "\n",
    "# Input layer\n",
    "grade_model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "\n",
    "# Hidden layers\n",
    "grade_model.add(Dense(128, activation='relu'))\n",
    "grade_model.add(Dropout(0.2))\n",
    "grade_model.add(Dense(64, activation='relu'))\n",
    "grade_model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "grade_model.add(Dense(1, activation='linear'))  # For regression to predict grade numerically\n",
    "\n",
    "# Compile the model\n",
    "grade_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "grade_model.fit(X_train_scaled, y_train_grade, epochs=50, batch_size=32, validation_data=(X_test_scaled, y_test_grade))\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_grade = grade_model.predict(X_test_scaled)\n",
    "y_pred_grade = y_pred_grade.round()  # Convert continuous output to nearest grade (0-10)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_grade, y_pred_grade)\n",
    "\n",
    "print(f\"Deep Learning Grade Prediction Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ec62f1d-5d36-4765-8ebf-3494344110d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50/50 [==============================] - 2s 14ms/step - loss: 599.1083 - mae: 16.9587 - val_loss: 126.9455 - val_mae: 9.4355\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 62.7688 - mae: 5.7769 - val_loss: 42.1328 - val_mae: 4.7589\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 41.1925 - mae: 4.5239 - val_loss: 35.7520 - val_mae: 4.5094\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 36.8616 - mae: 4.4144 - val_loss: 34.8067 - val_mae: 4.4662\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 36.2307 - mae: 4.3694 - val_loss: 35.0641 - val_mae: 4.4349\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 35.2021 - mae: 4.2664 - val_loss: 36.1602 - val_mae: 4.4549\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 34.3410 - mae: 4.1995 - val_loss: 31.4617 - val_mae: 4.2748\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 37.8198 - mae: 4.3355 - val_loss: 34.8981 - val_mae: 4.3657\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 36.0699 - mae: 4.2652 - val_loss: 30.5059 - val_mae: 4.1742\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 38.3846 - mae: 4.2839 - val_loss: 31.3184 - val_mae: 4.2117\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 37.5383 - mae: 4.2922 - val_loss: 29.7931 - val_mae: 4.1286\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 35.2805 - mae: 4.1184 - val_loss: 30.5313 - val_mae: 4.2032\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 32.5704 - mae: 4.0458 - val_loss: 28.2830 - val_mae: 4.0517\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 34.0734 - mae: 4.0632 - val_loss: 29.1293 - val_mae: 4.0589\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 29.5215 - mae: 3.9048 - val_loss: 34.3412 - val_mae: 4.2257\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 30.1091 - mae: 3.8683 - val_loss: 29.7453 - val_mae: 4.0337\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 33.4700 - mae: 3.9547 - val_loss: 33.7427 - val_mae: 4.1853\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 32.7267 - mae: 3.9062 - val_loss: 28.5949 - val_mae: 4.0560\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 30.3459 - mae: 3.7978 - val_loss: 28.8188 - val_mae: 4.0190\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 31.0327 - mae: 3.8679 - val_loss: 26.9907 - val_mae: 3.9349\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 30.2933 - mae: 3.7458 - val_loss: 28.2453 - val_mae: 4.0296\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 35.7017 - mae: 3.9493 - val_loss: 30.7046 - val_mae: 4.0623\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 34.2624 - mae: 3.8751 - val_loss: 27.7550 - val_mae: 3.9411\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 26.0536 - mae: 3.5102 - val_loss: 27.9707 - val_mae: 3.9746\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 29.9429 - mae: 3.7248 - val_loss: 33.9208 - val_mae: 4.0965\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 30.6621 - mae: 3.7619 - val_loss: 26.9579 - val_mae: 3.9744\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 27.6771 - mae: 3.5832 - val_loss: 34.6268 - val_mae: 4.0892\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 29.3980 - mae: 3.6602 - val_loss: 44.2461 - val_mae: 4.5253\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 27.9928 - mae: 3.6312 - val_loss: 30.8351 - val_mae: 3.9925\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 31.1813 - mae: 3.6754 - val_loss: 28.6567 - val_mae: 4.0461\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 25.4101 - mae: 3.4280 - val_loss: 34.1357 - val_mae: 4.1243\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 26.3098 - mae: 3.6149 - val_loss: 29.4510 - val_mae: 3.9526\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 23.7176 - mae: 3.3439 - val_loss: 30.1830 - val_mae: 3.9706\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 24.2142 - mae: 3.3925 - val_loss: 28.9208 - val_mae: 3.9372\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 24.2247 - mae: 3.3216 - val_loss: 29.0135 - val_mae: 3.8960\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 24.4964 - mae: 3.4215 - val_loss: 29.2252 - val_mae: 3.8880\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 25.6491 - mae: 3.3931 - val_loss: 26.6272 - val_mae: 3.8934\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 24.6997 - mae: 3.3512 - val_loss: 31.7974 - val_mae: 3.9867\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 25.1518 - mae: 3.4551 - val_loss: 29.4941 - val_mae: 3.9383\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 28.1898 - mae: 3.5579 - val_loss: 26.4392 - val_mae: 3.8118\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 29.0006 - mae: 3.5035 - val_loss: 28.1923 - val_mae: 3.8523\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 24.3462 - mae: 3.3557 - val_loss: 28.7126 - val_mae: 3.8618\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 23.6451 - mae: 3.2153 - val_loss: 26.3327 - val_mae: 3.8775\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 22.9586 - mae: 3.2092 - val_loss: 27.7001 - val_mae: 3.8929\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 22.5332 - mae: 3.2958 - val_loss: 29.7624 - val_mae: 3.9523\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 21.2322 - mae: 3.1637 - val_loss: 29.3528 - val_mae: 3.9061\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 25.5034 - mae: 3.3848 - val_loss: 28.8735 - val_mae: 3.8716\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 22.5587 - mae: 3.2811 - val_loss: 36.2441 - val_mae: 4.1450\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 21.8671 - mae: 3.2093 - val_loss: 27.4109 - val_mae: 3.8029\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 22.2335 - mae: 3.2116 - val_loss: 30.8834 - val_mae: 3.9794\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "Deep Learning Dropout Risk RMSE: 5.56\n",
      "Deep Learning Dropout Risk R-squared: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Build the neural network model for dropout risk prediction\n",
    "dropout_model = Sequential()\n",
    "\n",
    "# Input layer\n",
    "dropout_model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "\n",
    "# Hidden layers\n",
    "dropout_model.add(Dense(128, activation='relu'))\n",
    "dropout_model.add(Dropout(0.2))\n",
    "dropout_model.add(Dense(64, activation='relu'))\n",
    "dropout_model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "dropout_model.add(Dense(1, activation='linear'))  # For regression to predict dropout risk\n",
    "\n",
    "# Compile the model\n",
    "dropout_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "dropout_model.fit(X_train_scaled, y_train_dropout, epochs=50, batch_size=32, validation_data=(X_test_scaled, y_test_dropout))\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_dropout = dropout_model.predict(X_test_scaled)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Calculate RMSE (Root Mean Squared Error)\n",
    "dropout_rmse = mean_squared_error(y_test_dropout, y_pred_dropout) ** 0.5\n",
    "\n",
    "# Calculate R-squared score\n",
    "dropout_r2 = r2_score(y_test_dropout, y_pred_dropout)\n",
    "\n",
    "print(f\"Deep Learning Dropout Risk RMSE: {dropout_rmse:.2f}\")\n",
    "print(f\"Deep Learning Dropout Risk R-squared: {dropout_r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71cf1d0b-4d33-4d8a-b077-9f875ed8f52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 4ms/step\n",
      "Grade Predictions (first 5): [[ 9.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [ 9.]\n",
      " [ 8.]]\n",
      "Dropout Risk Predictions (first 5): [[ 1.6158726]\n",
      " [ 0.2122753]\n",
      " [54.53641  ]\n",
      " [ 4.081894 ]\n",
      " [ 5.3603287]]\n"
     ]
    }
   ],
   "source": [
    "# Predict Grade\n",
    "y_pred_grade = grade_model.predict(X_test_scaled)\n",
    "y_pred_grade = y_pred_grade.round()  # Round to nearest integer for grades (0-10)\n",
    "\n",
    "# Predict Dropout Risk (assuming dropout_model is already trained)\n",
    "y_pred_dropout = dropout_model.predict(X_test_scaled)\n",
    "\n",
    "# Print predictions for the first few test samples\n",
    "print(\"Grade Predictions (first 5):\", y_pred_grade[:5])\n",
    "print(\"Dropout Risk Predictions (first 5):\", y_pred_dropout[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e72c14d3-52e7-4d46-9e15-5c88a311e92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Actual Grades  Predicted Grades  Actual Dropout Risk  \\\n",
      "1860              9               9.0                 1.75   \n",
      "353              10              10.0                 0.00   \n",
      "1333              5               5.0                67.98   \n",
      "905               9               9.0                 3.91   \n",
      "1289              8               8.0                 8.45   \n",
      "1273              7               7.0                23.38   \n",
      "938               8               7.0                11.23   \n",
      "1731              7               7.0                27.71   \n",
      "65                7               8.0                25.85   \n",
      "1323              8               8.0                13.70   \n",
      "\n",
      "      Predicted Dropout Risk  \n",
      "1860                1.615873  \n",
      "353                 0.212275  \n",
      "1333               54.536411  \n",
      "905                 4.081894  \n",
      "1289                5.360329  \n",
      "1273               20.695372  \n",
      "938                 9.301775  \n",
      "1731               32.875168  \n",
      "65                 19.635881  \n",
      "1323                8.826236  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame to compare the actual and predicted values\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual Grades': y_test_grade,\n",
    "    'Predicted Grades': y_pred_grade.flatten(),  # Flatten the predictions array\n",
    "    'Actual Dropout Risk': y_test_dropout,\n",
    "    'Predicted Dropout Risk': y_pred_dropout.flatten()  # Flatten the predictions array\n",
    "})\n",
    "\n",
    "# Display the first 10 rows to compare\n",
    "print(comparison_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "112f17cb-bda0-4208-86ac-e0dba9a2918d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save the grade prediction model\n",
    "grade_model.save('grade_prediction_model1.h5')\n",
    "\n",
    "# Save the dropout risk prediction model\n",
    "dropout_model.save('dropout_risk_prediction_model1.h5')\n",
    "\n",
    "print(\"Models saved successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334072cf-e677-48ad-b868-d209e43631b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
